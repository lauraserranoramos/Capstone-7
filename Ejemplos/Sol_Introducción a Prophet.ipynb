{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/mCIDaeNnb.png\" alt=\"Logo CiDAEN\" align=\"right\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br><br><br>\n",
    "<h2><font color=\"#00586D\" size=4>Módulo 7</font></h2>\n",
    "\n",
    "\n",
    "\n",
    "<h1><font color=\"#00586D\" size=5>Usando Facebook Prophet en Python</font></h1>\n",
    "\n",
    "<br><br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#00586D\" size=3>Enrique González</font><br>\n",
    "<font color=\"#00586D\" size=3>Máster en Ciencia de Datos e Ingeniería de Datos en la Nube III </font><br>\n",
    "<font color=\"#00586D\" size=3>Universidad de Castilla-La Mancha</font>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"indice\"></a>\n",
    "<h2><font color=\"#00586D\" size=5>Índice</font></h2>\n",
    "\n",
    "\n",
    "* [1. Introducción](#section1)\n",
    "* [2. Modelo de pronóstico](#section2)\n",
    "* [3. Evaluación de modelos](#section3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optimiza los gráficos para pantalla retina\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "# Por defecto usamos el backend inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Oculta warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# La libreta ocupa así el 95% de la pantalla\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section1\"></a>\n",
    "## <font color=\"#00586D\"> 1. Introducción</font>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta práctica introducimos la librería Facebook Prophet para la creación de pronósticos. Esta librería tiene la ventaja de ser muy sencilla de usar y además incluir bastante funcionalidad útil para la visualización y evaluación de los resultados de pronóstico. Es ideal en series con grandes efectos estacionales, y cuando tenemos disponibles varios periodos estacionales. Asimismo, Prophet es robusto tanto a datos perdidos como a cambios en la tendencia. Todo esto, manteniendo una gran facilidad de uso lo que la convierte en una muy buena alternativa para obtener modelos de pronóstico en solo unas pocas líneas de código. \n",
    "\n",
    "Quizá lo más complicado de esta librería es instalarla. Para hacerlo os recomendamos seguir paso a paso las recomendaciones que dan desde el proyecto [para vuestro entorno específico](https://facebook.github.io/prophet/docs/installation.html#python), sobre todo en lo relativo a `pystan`.\n",
    "\n",
    "Podéis conocer más sobre este modelo en la [página oficial del proyecto](https://facebook.github.io/prophet/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<i class=\"fa fa-exclamation-circle\" aria-hidden=\"true\"></i>\n",
    "__Recordad__: Cread un `virtualenv` e instalad las librerias del `requirement.txt`para poder continuar con la práctica.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta práctica continuaremos con los conjuntos de datos de las prácticas anteriores. Para facilitar el acceso a la descripción de estos datos, os la incluyo a continuación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Son datos meteorológicos de dos estaciones meteorológicas españolas, la estación meteorológica del Retiro en Madrid y la estación meteorológica de La Coruña. Estos datos los podéis encontrar en `datos/meteo_retiro.csv`, con datos meteorológicos diarios desde el 1 de Enero de 1920 y `datos/meteo_coruña.csv`, con datos meteorológicos desde el 1 de Octubre de 1930.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación os indicamos la descripción de cada una de las columnas presentes en estas tablas:\n",
    "\n",
    "- `FECHA`: Fecha en formato (aaaa-mm-dd) . Si lo abre con una hoja de cálculo, es posible que interprete el campo como fecha y lo vea en el formato habitual dd/mm/aaaa\n",
    "- `INDICATIVO`: Identificador de Estación Meteorológica (Valor de 4 ó 5 caracteres)\n",
    "- `NOMBRE`: Nombre de la Estación\n",
    "- `PROVINCIA`: Provincia en la que se encuentra\n",
    "- `ALTITUD`: Altitud (metros)\n",
    "- `TMEDIA`: Temperatura media (ºC)\n",
    "- `PRECIPITACION`: Precipitación (mm = l/m2)\n",
    "- `TMIN`: Temperatura minima (ºC)\n",
    "- `HORATMIN`: Hora de Temperatura mínima (hh:mm)\n",
    "- `TMAX`: Temperatura Máxima (ºC)\n",
    "- `HORATMAX`: Hora de Temperatura máxima (hh:mm)\n",
    "- `DIR`: Dirección del viento (decenas de grado)\n",
    "- `VELMEDIA`: Velocidad media (m/s)\n",
    "- `RACHA`: Racha (m/s)\n",
    "- `HORARACHA`: Hora Racha (hh:mm)\n",
    "- `SOL`: Horas de Sol (horas)\n",
    "- `PRESMAX`: Presión máxima (hPa)\n",
    "- `HORAPRESMAX`: Hora de Presión Máxima (hh:mm)\n",
    "- `PRESMIN`: Presión Mínima (hPa)\n",
    "- `HORAPRESMIN`: Hora de Presión Mínima (hh:mm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section2\"></a>\n",
    "## <font color=\"#00586D\"> 2. Modelo de pronóstico</font>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear un modelo con Prophet es bastante sencillo. Solo hay que tener en cuenta algunas suposiciones que hace el modelo en cuanto a los datos de entrada. Para Prophet, el conjunto de datos de entrada tiene que tener dos coumnas:\n",
    "- Una columna con nombre `ds`, que indica la marca de tiempo del dato. Los datos tendrán que tener una marca de tiempo siguiendo el formato `YYYY-MM-DD HH:MM:SS` y pueden contar con diferentes frecuencias: minutal, horaria, diaria, mensual...\n",
    "- Una columna `y` con los valores de la serie temporal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto,el primer paso para poder utilizar Prophet es procesar la serie de datos. Vamos a comenzar cargando datos y dividiéndolos en entrenamiento y test como en prácticas anteriores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/meteo_retiro.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ts \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/meteo_retiro.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFECHA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFECHA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlatin9\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2000\u001b[39m\u001b[38;5;124m'\u001b[39m:, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTMEDIA\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(ts)\n\u001b[1;32m      9\u001b[0m split \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m \u001b[38;5;66;03m# % de datos para test\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/meteo_retiro.csv'"
     ]
    }
   ],
   "source": [
    "ts = pd.read_csv(\n",
    "    './data/meteo_retiro.csv', \n",
    "    sep=';', \n",
    "    parse_dates=['FECHA'], \n",
    "    index_col='FECHA', \n",
    "    encoding='latin9'\n",
    ").loc['2000':, 'TMEDIA']\n",
    "n = len(ts)\n",
    "split = 0.2 # % de datos para test\n",
    "n_training = int((1-split)*n)\n",
    "training = ts[:n_training]\n",
    "test = ts[n_training:]\n",
    "training.plot(figsize=(20,5), color='firebrick', ls='-');\n",
    "test.plot(figsize=(20,5), color='silver', ls='-');\n",
    "plt.legend(['Training', 'Test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos tienen la siguiente forma. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para transformarlos en el formato esperado por Prophet, tomaremos el índice temporal de los datos y crearemos una columna a partir de este. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_prophet = training.reset_index().rename(columns={'FECHA': 'ds', 'TMEDIA': 'y'})\n",
    "test_prophet = test.reset_index().rename(columns={'FECHA': 'ds', 'TMEDIA': 'y'})\n",
    "training_prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos los datos preparados para ser utilizados por el modelo de Prophet. A continuación, entrenamos con los datos de _training_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "m = Prophet()\n",
    "m.fit(training_prophet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para probar el modelo podemos usar el método `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = m.predict(test_prophet)\n",
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta forma, Prophet nos proporciona de forma muy sencilla tanto la estimación del valor de temperatura, como unos intervalos de confianza (por omisión, 80%) sobre esta predicción. Se puede modificar el tipo de intervalos de confianza generados en el momento de crear el modelo de prophet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Prophet(interval_width=0.95)\n",
    "m.fit(training_prophet)\n",
    "forecast = m.predict(test_prophet)\n",
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos visualizar el resultado del pronóstico de la siguiente forma, reseteando el índice temporal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.plot(figsize=(20,5), color='firebrick', ls='-');\n",
    "test.plot(figsize=(20,5), color='silver', ls='-');\n",
    "pred = forecast.set_index('ds')['yhat']\n",
    "pred.plot(figsize=(20,5), color='slateblue', ls='-');\n",
    "plt.legend(['Training', 'Test', 'Forecast'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O también podemos visualizar la predicción usando el método `plot` del modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = m.plot(forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenado nuestro modelo, normalmente nos interesará guardarlo. Para ello, la forma recomendada es usar las utilidades de serialización de Prophet y el paquete `json`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from prophet.serialize import model_to_json, model_from_json\n",
    "\n",
    "with open('modelo_pronostico.json', 'w') as fout:\n",
    "    json.dump(model_to_json(m), fout)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cargarlo, podéis usar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('modelo_pronostico.json', 'r') as fin:\n",
    "    m_saved = model_from_json(json.load(fin))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = m_saved.plot(forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<i class=\"fa fa-exclamation-circle\" aria-hidden=\"true\"></i>\n",
    "__Importante__: Este modelo guardado de esta forma solo os servirá para hacer predicciones. No podréis utilizarlo (como veremos a continuación) con el método `cross_validation` ya que requeriría entrenar otra vez el modelo (y el objeto resultante de la serialización no lo permite)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#00586D\"></i></font></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <font color=\"#00586D\"> <i class=\"fa fa-pencil-square-o\" aria-hidden=\"true\" style=\"color:#113D68\"></i> Ejercicio 1</font>\n",
    "\n",
    "Crea un modelo de Prophet para el pronóstico de la temperatura máxima y mínima en Madrid usando los datos del retiro. Estas series están disponibles con los nombres TMAX y TMIN respectivamente. Múestra estos dos pronósticos en un gráfico junto con el pronóstico de la temperatura media creado anteriormente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUCIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.read_csv(\n",
    "    './data/meteo_retiro.csv', \n",
    "    sep=';', \n",
    "    parse_dates=['FECHA'], \n",
    "    index_col='FECHA', \n",
    "    encoding='latin9'\n",
    ").loc['2000':, 'TMAX']\n",
    "n = len(ts)\n",
    "split = 0.2 # % de datos para test\n",
    "n_training = int((1-split)*n)\n",
    "training_max_ts = ts[:n_training]\n",
    "test_max_ts = ts[n_training:]\n",
    "training_max = training_max_ts.reset_index().rename(columns={'FECHA': 'ds', 'TMAX': 'y'})\n",
    "test_max = test_max_ts.reset_index().rename(columns={'FECHA': 'ds', 'TMAX': 'y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.read_csv(\n",
    "    './data/meteo_retiro.csv', \n",
    "    sep=';', \n",
    "    parse_dates=['FECHA'], \n",
    "    index_col='FECHA', \n",
    "    encoding='latin9'\n",
    ").loc['2000':, 'TMIN']\n",
    "n = len(ts)\n",
    "split = 0.2 # % de datos para test\n",
    "n_training = int((1-split)*n)\n",
    "training_min = ts[:n_training]\n",
    "test_min = ts[n_training:]\n",
    "training_min = training_min.reset_index().rename(columns={'FECHA': 'ds', 'TMIN': 'y'})\n",
    "test_min = test_min.reset_index().rename(columns={'FECHA': 'ds', 'TMIN': 'y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_max = Prophet()\n",
    "m_max.fit(training_max)\n",
    "forecast = m_max.predict(test_max)\n",
    "pred_max = forecast.set_index('ds')['yhat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_min = Prophet()\n",
    "m_min.fit(training_min)\n",
    "forecast = m_min.predict(test_min)\n",
    "pred_min = forecast.set_index('ds')['yhat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.plot(figsize=(20,5), color='firebrick', ls='-');\n",
    "test.plot(figsize=(20,5), color='silver', ls='-');\n",
    "pred.plot(figsize=(20,5), color='slateblue', ls='-');\n",
    "pred_max.plot(figsize=(20,5), color='darkorange', ls='-');\n",
    "pred_min.plot(figsize=(20,5), color='darkgreen', ls='-');\n",
    "plt.legend(['Training', 'Test', 'Forecast'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('modelo_max2.json', 'w') as fout:\n",
    "    json.dump(model_to_json(m_max), fout)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado esperado:\n",
    "\n",
    "![resultado](img/ej1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"><font size=4> <i class=\"fa fa-check-square-o\" aria-hidden=\"true\" style=\"color:#00586D\"></i></font></div>\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section3\"></a>\n",
    "## <font color=\"#00586D\"> 3. Evaluación de modelos </font>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos evaluar los modelos de Prophet tal como veíamos en prácticas anteriores, usando `scikit-learn`. En este caso optamos por rellenar los NA para que no nos de problemas la función de evaluación, aunque también podríamos haberlos eliminado.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "mean_absolute_error(test.fillna(method='ffill'), pred.fillna(method='ffill'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como alternativa, Prophet nos proporciona un método para facilitarnos la evaluación por medio de validación cruzada temporal. Para usarla, deberemos definir 3 componentes. \n",
    "- `initial`: Número de periodos de datos inicial. A partir de este, se empezará la evaluación. Por ejemplo, si indicamos 2 años, se utilizarán esos dos años como conjunto de entrenamiento de partida que luego se irá aumentando a medida que se incrementa el punto de corte.  \n",
    "- `horizon`: el horizonte que se pronosticará para realizar la evaluación. Por ejemplo, partiendo de los datos de entrenamiento de 2 años, se realiza un pronóstico de 1 año, sobre el que se aplicará la métrica de evaluación. \n",
    "- `period`: Marca cada cuantos periodos se realizará una evaluación. Esto es, si nuestro periodo inicial es de 2 años, nuestro horizonte es de 1 año y  nuestro periodo es de 6 meses, se evaluará, en el primer caso, un año desde los 2 años iniciales, en el segundo, un año entrenando con los 2 años iniciales más el periodo de 6 meses, y así se continuaría hasta acabar con los datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para utilizarlo, tendréis que usar el siguiente método. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet.diagnostics import cross_validation\n",
    "\n",
    "example_cv = cross_validation(m, initial='730 days', period='180 days', horizon = '365 days')\n",
    "example_cv.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso hemos usado, aproximadamente, dos años de periodo inicial, medio año de periodo y un horizonte de un año. Como resultado obtenemos la predicción para todos los horizontes, usando los datos previos a este para el entrenamiento. Como el periodo no coincide con el tamaño del horizonte, en muchos casos tendremos el doble de predicciones. Para visualizar los datos, vamos a agregar los datos repetidos por la media. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_pred = example_cv.set_index('ds').sort_index()['yhat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_pred['2004':].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = cv_pred.resample('D').mean()\n",
    "prediction['2004':].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a visualizar el resultado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.plot(figsize=(20,5), color='silver', ls='-');\n",
    "prediction.plot(figsize=(20,5), color='darkgreen', ls='-');\n",
    "plt.legend(['Training', 'Forecast'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asimismo, Prophet nos permite obtener una serie de métricas de rendimiento teniendo en cuenta el número de días desde el último día de entrenamiento. Eso sí, para el cálculo de cada métrica utiliza una ventana deslizante sobre las predicciones, que tiene un tamaño del 10% de los datos. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet.diagnostics import performance_metrics\n",
    "df_p = performance_metrics(example_cv)\n",
    "df_p.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prophet también nos permite ver estos resultados en una gráfica. Por ejemplo, veamos el MAE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet.plot import plot_cross_validation_metric\n",
    "fig = plot_cross_validation_metric(example_cv, metric='mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta forma podemos ver si nuestro modelo pierde potencia a medida que avanzamos en el horizonte. En nuestro caso, sin embargo, parece que la calidad del pronóstico es más o menos constante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#00586D\"></i></font></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <font color=\"#00586D\"> <i class=\"fa fa-pencil-square-o\" aria-hidden=\"true\" style=\"color:#113D68\"></i> Ejercicio 2</font>\n",
    "\n",
    "Evalúa tu modelo de pronóstico para TMAX que creaste en el Ejercicio 1 mostrando como evoluciona el MAE a medida que se avanza en el horizonte. Obten también el MAE de tú pronóstico para todos los valores del horizonte, pero en este caso, no rellenes los valores NaN si no eliminalos de forma que puedas calcular el MAE solo con los valores adecuados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet.diagnostics import cross_validation\n",
    "\n",
    "example_cv = cross_validation(m_max, initial='730 days', period='180 days', horizon = '365 days')\n",
    "example_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_max_ts.plot(figsize=(20,5), color='silver', ls='-');\n",
    "example_cv.set_index('ds')['yhat'].sort_index().plot(figsize=(20,5), color='darkgreen', ls='-');\n",
    "plt.legend(['Training', 'Forecast'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet.plot import plot_cross_validation_metric\n",
    "fig = plot_cross_validation_metric(example_cv, metric='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_pred = example_cv.set_index('ds').sort_index()['yhat']\n",
    "prediction = cv_pred.resample('D').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_date = prediction.index[0]\n",
    "last_date = prediction.index[-1]\n",
    "expected = training_max_ts[first_date:last_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_eval = pd.concat([expected, prediction], axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(to_eval.iloc[:,0], to_eval.iloc[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado esperado:\n",
    "- MAE: 2.9758\n",
    "\n",
    "![resultado](img/ej2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"><font size=4> <i class=\"fa fa-check-square-o\" aria-hidden=\"true\" style=\"color:#00586D\"></i></font></div>\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-coffee\" aria-hidden=\"true\" style=\"color:#00586D\"></i> </font></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
